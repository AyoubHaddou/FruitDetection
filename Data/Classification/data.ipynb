{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_compteur_fruit = {}\n",
    "i=0\n",
    "for root, dir, filenames in os.walk('fruits-360_dataset/fruits-360/Training'):\n",
    "    for filename in filenames:\n",
    "        \n",
    "        name = root.split(\"\\\\\")[-1]\n",
    "        n = name.split(\" \")[0]\n",
    "        if n in list(dic_compteur_fruit.keys()):\n",
    "            dic_compteur_fruit[n] += 1\n",
    "        else:\n",
    "            dic_compteur_fruit[n] = 0\n",
    "        old_path = root + \"/\" + filename\n",
    "        newpath = \"/\".join(root.split(\"/\")[0:-1]) + \"/train/\" + n + \"/\" + n + \"_\" + str(dic_compteur_fruit[n])+\".jpg\"\n",
    "        os.rename(old_path,newpath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_compteur_fruit = {}\n",
    "i=0\n",
    "for root, dir, filenames in os.walk('fruits-360_dataset/fruits-360/Test'):\n",
    "    for filename in filenames:\n",
    "        \n",
    "        name = root.split(\"\\\\\")[-1]\n",
    "        n = name.split(\" \")[0]\n",
    "        if n in list(dic_compteur_fruit.keys()):\n",
    "            dic_compteur_fruit[n] += 1\n",
    "        else:\n",
    "            dic_compteur_fruit[n] = 0\n",
    "        old_path = root + \"/\" + filename\n",
    "        newpath = \"/\".join(root.split(\"/\")[0:-1]) + \"/testing/\" + n + \"/\" + n + \"_\" + str(dic_compteur_fruit[n])+\".jpg\"\n",
    "        os.rename(old_path,newpath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_compteur_fruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n",
    "    dtype=tf.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "IMG_SIZE = 75\n",
    "TRAIN_DIR = 'fruits-360_dataset/fruits-360/train'\n",
    "TEST_DIR = 'fruits-360_dataset/fruits-360/testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70420 images belonging to 78 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batch = train_gen.flow_from_directory(\n",
    "    directory=TRAIN_DIR,\n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"sparse\",\n",
    "    seed=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22993 images belonging to 78 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batch = train_gen.flow_from_directory(\n",
    "    directory=TEST_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode = 'sparse',\n",
    "    seed=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMG_SIZE,IMG_SIZE) + (3,)\n",
    "base_model = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(78, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 6/23 [======>.......................] - ETA: 20s - loss: 0.1744 - accuracy: 0.9583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\boure\\anaconda3\\envs\\aifruits\\lib\\site-packages\\PIL\\Image.py:976: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 42s 2s/step - loss: 0.1689 - accuracy: 0.9540 - val_loss: 0.2182 - val_accuracy: 0.9379\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 41s 2s/step - loss: 0.1612 - accuracy: 0.9582 - val_loss: 0.2169 - val_accuracy: 0.9347\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 45s 2s/step - loss: 0.1574 - accuracy: 0.9589 - val_loss: 0.2119 - val_accuracy: 0.9389\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 43s 2s/step - loss: 0.1488 - accuracy: 0.9589 - val_loss: 0.2016 - val_accuracy: 0.9411\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 42s 2s/step - loss: 0.1550 - accuracy: 0.9591 - val_loss: 0.2269 - val_accuracy: 0.9343\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 42s 2s/step - loss: 0.1596 - accuracy: 0.9545 - val_loss: 0.1804 - val_accuracy: 0.9489\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 44s 2s/step - loss: 0.1445 - accuracy: 0.9604 - val_loss: 0.2185 - val_accuracy: 0.9396\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 43s 2s/step - loss: 0.1423 - accuracy: 0.9640 - val_loss: 0.1937 - val_accuracy: 0.9414\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 40s 2s/step - loss: 0.1374 - accuracy: 0.9631 - val_loss: 0.1874 - val_accuracy: 0.9496\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(train_batch, \n",
    "            epochs=50,\n",
    "            steps_per_epoch = 6000 // BATCH_SIZE,\n",
    "            validation_data = test_batch,\n",
    "            validation_steps = 3000 // BATCH_SIZE,\n",
    "            callbacks=tf.keras.callbacks.EarlyStopping(patience=3)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\boure\\anaconda3\\envs\\aifruits\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "model.save(\"aifruits_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with real image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicting_img = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n",
    "    dtype=tf.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_TEST_DIR = 'fruits-360_dataset/fruits-360/real_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "img_transform = predicting_img.flow_from_directory(\n",
    "    directory=REAL_TEST_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(img_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_labels = [\n",
    "    \"Apple\", \"Apricot\",\"Avocado\",\"Banana\", \"Beetroot\",\"Blueberry\",\"Cabbage\",\n",
    "    \"Cactus\",\"Cantaloupe\",\"Caspicum\",\"Carambula\",\"Carrot\",\"Cauliflower\",\"Cherry\",\n",
    "    \"Chestnut\",\"Clementine\",\"Cocos\",\"Corn\",\"Cucumber\",\"Dates\",\"Eggplant\",\"Fig\",\n",
    "    \"Garlic\",\"Ginger\",\"Granadilla\",\"Grape\",\"Grapefruit\",\"Guava\",\"Hazelnut\",\n",
    "    \"Huckleberry\",\"Jalapeno\",\"Kaki\",\"Kiwi\",\"Kohlrabi\",\"Kumquats\",\"Lemon\",\"Limes\",\n",
    "    \"Lychee\",\"Mandarine\",\"Mango\",\"Mangostan\",\"Maracuja\",\"Melon\",\"Mulberry\",\n",
    "    \"Nectarine\",\"Nut\",\"Onion\",\"Orange\",\"Papaya\",\"Passion\",\"Peach\",\"Pear\",\n",
    "    \"Peas\",\"Pepino\",\"Pepper\",\"Physalis\",\"Pineapple\",\"Pitahaya\",\"Plum\",\"Pomegranate\",\n",
    "    \"Pomelo\",\"Potato\",\"Quince\",\"Quince\",\"Raddish\",\"Rambutan\",\"Raspberry\",\"Redcurrant\",\n",
    "    \"Salak\",\"Soybeans\",\"Spinach\",\"Strawberry\",\"Tamarillo\",\"Tangelo\",\"Tomato\",\"Turnip\",\n",
    "    \"Walnut\",\"Watermelon\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Watermelon', 'Mangostan', 'Apple', 'Physalis', 'Caspicum']\n",
      "['Maracuja', 'Watermelon', 'Pomelo', 'Peas', 'Strawberry']\n",
      "['Cherry', 'Mangostan', 'Caspicum', 'Tomato', 'Apple']\n",
      "['Maracuja', 'Watermelon', 'Pomelo', 'Peas', 'Strawberry']\n",
      "['Physalis', 'Cherry', 'Tamarillo', 'Tomato', 'Apple']\n",
      "['Tomato', 'Jalapeno', 'Cherry', 'Pomelo', 'Orange']\n",
      "['Orange', 'Peas', 'Apple', 'Garlic', 'Turnip']\n",
      "['Apple', 'Pomegranate', 'Mangostan', 'Tomato', 'Pomelo']\n",
      "['Pomegranate', 'Tomato', 'Apple', 'Pomelo', 'Cherry']\n",
      "['Cherry', 'Physalis', 'Peas', 'Tomato', 'Apple']\n"
     ]
    }
   ],
   "source": [
    "for item in prediction:\n",
    "    liste=[]\n",
    "    for pred in np.argsort(item)[-5:]:\n",
    "        liste.append(list_labels[pred])\n",
    "    print(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2620113\n",
      "0.87740034\n",
      "0.625669\n",
      "0.87740034\n",
      "0.7607616\n",
      "0.29217407\n",
      "0.64259315\n",
      "0.47031373\n",
      "0.42827544\n",
      "0.9722272\n"
     ]
    }
   ],
   "source": [
    "for item in prediction:\n",
    "    print(np.max(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 75, 75, 3)]       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 3, 3, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 78)                40014     \n",
      "=================================================================\n",
      "Total params: 24,939,470\n",
      "Trainable params: 1,351,758\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.trainable = False\n",
    "for i in range(len(base_model.layers)):\n",
    "    if i>=len(base_model.layers)*0.75:\n",
    "        base_model.layers[i].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 43s 2s/step - loss: 0.1490 - accuracy: 0.9564 - val_loss: 0.2306 - val_accuracy: 0.9379\n",
      "Epoch 2/50\n",
      "12/23 [==============>...............] - ETA: 13s - loss: 0.1611 - accuracy: 0.9518"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\boure\\anaconda3\\envs\\aifruits\\lib\\site-packages\\PIL\\Image.py:976: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 40s 2s/step - loss: 0.1570 - accuracy: 0.9543 - val_loss: 0.1728 - val_accuracy: 0.9499\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 38s 2s/step - loss: 0.1448 - accuracy: 0.9613 - val_loss: 0.2028 - val_accuracy: 0.9425\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 39s 2s/step - loss: 0.1364 - accuracy: 0.9618 - val_loss: 0.1720 - val_accuracy: 0.9492\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 38s 2s/step - loss: 0.1196 - accuracy: 0.9660 - val_loss: 0.1723 - val_accuracy: 0.9517\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 39s 2s/step - loss: 0.1255 - accuracy: 0.9631 - val_loss: 0.1650 - val_accuracy: 0.9499\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 39s 2s/step - loss: 0.1244 - accuracy: 0.9650 - val_loss: 0.1781 - val_accuracy: 0.9510\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 39s 2s/step - loss: 0.1272 - accuracy: 0.9637 - val_loss: 0.2074 - val_accuracy: 0.9425\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 37s 2s/step - loss: 0.1152 - accuracy: 0.9666 - val_loss: 0.1700 - val_accuracy: 0.9499\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(train_batch, \n",
    "            epochs=50,\n",
    "            steps_per_epoch = 6000 // BATCH_SIZE,\n",
    "            validation_data = test_batch,\n",
    "            validation_steps = 3000 // BATCH_SIZE,\n",
    "            callbacks=tf.keras.callbacks.EarlyStopping(patience=3)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(img_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mangostan', 'Soybeans', 'Cherry', 'Tomato', 'Apple']\n",
      "['Cauliflower', 'Peas', 'Apple', 'Garlic', 'Turnip']\n",
      "['Pomelo', 'Cherry', 'Tamarillo', 'Tomato', 'Apple']\n",
      "['Beetroot', 'Mangostan', 'Tomato', 'Apple', 'Pomelo']\n",
      "['Peas', 'Mangostan', 'Watermelon', 'Caspicum', 'Apple']\n",
      "['Maracuja', 'Watermelon', 'Pomelo', 'Peas', 'Strawberry']\n",
      "['Jalapeno', 'Tomato', 'Cherry', 'Apple', 'Pomelo']\n",
      "['Maracuja', 'Watermelon', 'Pomelo', 'Peas', 'Strawberry']\n",
      "['Orange', 'Apple', 'Jalapeno', 'Tomato', 'Pomelo']\n",
      "['Cherry', 'Redcurrant', 'Peas', 'Pomelo', 'Apple']\n"
     ]
    }
   ],
   "source": [
    "for item in prediction:\n",
    "    liste=[]\n",
    "    for pred in np.argsort(item)[-5:]:\n",
    "        liste.append(list_labels[pred])\n",
    "    print(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\boure\\anaconda3\\envs\\aifruits\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "model.save(\"aifruits_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.trainable = False\n",
    "count=0\n",
    "for i in range(len(base_model.layers)):\n",
    "    if i>=len(base_model.layers)*0.5:\n",
    "        base_model.layers[i].trainable = True\n",
    "        count+=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1288 - accuracy: 0.9625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\boure\\anaconda3\\envs\\aifruits\\lib\\site-packages\\PIL\\Image.py:976: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 42s 2s/step - loss: 0.1288 - accuracy: 0.9625 - val_loss: 0.1660 - val_accuracy: 0.9492\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 38s 2s/step - loss: 0.1219 - accuracy: 0.9662 - val_loss: 0.1523 - val_accuracy: 0.9545\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 38s 2s/step - loss: 0.1099 - accuracy: 0.9681 - val_loss: 0.1492 - val_accuracy: 0.9528\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 39s 2s/step - loss: 0.1104 - accuracy: 0.9676 - val_loss: 0.1541 - val_accuracy: 0.9503\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 38s 2s/step - loss: 0.1103 - accuracy: 0.9682 - val_loss: 0.1631 - val_accuracy: 0.9542\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 38s 2s/step - loss: 0.1084 - accuracy: 0.9721 - val_loss: 0.1678 - val_accuracy: 0.9517\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(train_batch, \n",
    "            epochs=50,\n",
    "            steps_per_epoch = 6000 // BATCH_SIZE,\n",
    "            validation_data = test_batch,\n",
    "            validation_steps = 3000 // BATCH_SIZE,\n",
    "            callbacks=tf.keras.callbacks.EarlyStopping(patience=3)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(img_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ginger', 'Apple', 'Orange', 'Turnip', 'Garlic']\n",
      "['Jalapeno', 'Pomelo', 'Tomato', 'Cherry', 'Apple']\n",
      "['Tomato', 'Apple', 'Orange', 'Pomelo', 'Cherry']\n",
      "['Beetroot', 'Tomato', 'Mangostan', 'Apple', 'Pomelo']\n",
      "['Mangostan', 'Cherry', 'Tamarillo', 'Tomato', 'Apple']\n",
      "['Caspicum', 'Soybeans', 'Cherry', 'Tomato', 'Apple']\n",
      "['Raddish', 'Peas', 'Apple', 'Pomelo', 'Strawberry']\n",
      "['Peas', 'Cherry', 'Physalis', 'Pomelo', 'Apple']\n",
      "['Raddish', 'Peas', 'Apple', 'Pomelo', 'Strawberry']\n",
      "['Physalis', 'Jalapeno', 'Mangostan', 'Caspicum', 'Apple']\n"
     ]
    }
   ],
   "source": [
    "for item in prediction:\n",
    "    liste=[]\n",
    "    for pred in np.argsort(item)[-5:]:\n",
    "        liste.append(list_labels[pred])\n",
    "    print(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"aifruits_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.trainable = False\n",
    "count=0\n",
    "for i in range(len(base_model.layers)):\n",
    "    if i>=len(base_model.layers)*0.25:\n",
    "        base_model.layers[i].trainable = True\n",
    "        count+=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/23 [=======================>......] - ETA: 4s - loss: 0.1121 - accuracy: 0.9700"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\boure\\anaconda3\\envs\\aifruits\\lib\\site-packages\\PIL\\Image.py:976: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 41s 2s/step - loss: 0.1112 - accuracy: 0.9704 - val_loss: 0.1768 - val_accuracy: 0.9485\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 38s 2s/step - loss: 0.0947 - accuracy: 0.9718 - val_loss: 0.1670 - val_accuracy: 0.9496\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 38s 2s/step - loss: 0.1084 - accuracy: 0.9682 - val_loss: 0.1446 - val_accuracy: 0.9624\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 41s 2s/step - loss: 0.0970 - accuracy: 0.9737 - val_loss: 0.1606 - val_accuracy: 0.9524\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 40s 2s/step - loss: 0.1016 - accuracy: 0.9706 - val_loss: 0.1508 - val_accuracy: 0.9531\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 40s 2s/step - loss: 0.1028 - accuracy: 0.9701 - val_loss: 0.1528 - val_accuracy: 0.9535\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(train_batch, \n",
    "            epochs=50,\n",
    "            steps_per_epoch = 6000 // BATCH_SIZE,\n",
    "            validation_data = test_batch,\n",
    "            validation_steps = 3000 // BATCH_SIZE,\n",
    "            callbacks=tf.keras.callbacks.EarlyStopping(patience=3)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000010F9F906E18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(img_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cherry', 'Jalapeno', 'Orange', 'Pomelo', 'Apple']\n",
      "['Caspicum', 'Mangostan', 'Tomato', 'Cherry', 'Apple']\n",
      "['Watermelon', 'Caspicum', 'Physalis', 'Mangostan', 'Apple']\n",
      "['Raddish', 'Peas', 'Apple', 'Pomelo', 'Strawberry']\n",
      "['Cherry', 'Tomato', 'Pomelo', 'Jalapeno', 'Apple']\n",
      "['Tomato', 'Beetroot', 'Apple', 'Mangostan', 'Pomelo']\n",
      "['Orange', 'Cauliflower', 'Turnip', 'Apple', 'Garlic']\n",
      "['Raddish', 'Peas', 'Apple', 'Pomelo', 'Strawberry']\n",
      "['Physalis', 'Cherry', 'Tomato', 'Tamarillo', 'Apple']\n",
      "['Peas', 'Redcurrant', 'Physalis', 'Pomelo', 'Apple']\n"
     ]
    }
   ],
   "source": [
    "for item in prediction:\n",
    "    liste=[]\n",
    "    for pred in np.argsort(item)[-5:]:\n",
    "        liste.append(list_labels[pred])\n",
    "    print(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"aifruits_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.trainable = False\n",
    "count=0\n",
    "for i in range(len(base_model.layers)):\n",
    "    if i>=len(base_model.layers)*0.15:\n",
    "        base_model.layers[i].trainable = True\n",
    "        count+=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 41s 2s/step - loss: 0.1065 - accuracy: 0.9706 - val_loss: 0.1560 - val_accuracy: 0.9560\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 38s 2s/step - loss: 0.1039 - accuracy: 0.9701 - val_loss: 0.1360 - val_accuracy: 0.9620\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 39s 2s/step - loss: 0.0967 - accuracy: 0.9724 - val_loss: 0.1396 - val_accuracy: 0.9581\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 39s 2s/step - loss: 0.0916 - accuracy: 0.9737 - val_loss: 0.1467 - val_accuracy: 0.9592\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 40s 2s/step - loss: 0.0910 - accuracy: 0.9759 - val_loss: 0.1310 - val_accuracy: 0.9656\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 39s 2s/step - loss: 0.0816 - accuracy: 0.9774 - val_loss: 0.1330 - val_accuracy: 0.9595\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 40s 2s/step - loss: 0.0886 - accuracy: 0.9738 - val_loss: 0.1475 - val_accuracy: 0.9624\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 41s 2s/step - loss: 0.0895 - accuracy: 0.9742 - val_loss: 0.1306 - val_accuracy: 0.9624\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 39s 2s/step - loss: 0.0971 - accuracy: 0.9718 - val_loss: 0.1140 - val_accuracy: 0.9670\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 39s 2s/step - loss: 0.0834 - accuracy: 0.9757 - val_loss: 0.1334 - val_accuracy: 0.9631\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 39s 2s/step - loss: 0.0839 - accuracy: 0.9752 - val_loss: 0.1332 - val_accuracy: 0.9645\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 38s 2s/step - loss: 0.0830 - accuracy: 0.9745 - val_loss: 0.1236 - val_accuracy: 0.9616\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(train_batch, \n",
    "            epochs=50,\n",
    "            steps_per_epoch = 6000 // BATCH_SIZE,\n",
    "            validation_data = test_batch,\n",
    "            validation_steps = 3000 // BATCH_SIZE,\n",
    "            callbacks=tf.keras.callbacks.EarlyStopping(patience=3)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000010F9146D488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(img_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beetroot', 'Apple', 'Tomato', 'Mangostan', 'Pomelo']\n",
      "['Caspicum', 'Watermelon', 'Mangostan', 'Physalis', 'Apple']\n",
      "['Orange', 'Caspicum', 'Mangostan', 'Tomato', 'Apple']\n",
      "['Peas', 'Caspicum', 'Physalis', 'Pomelo', 'Apple']\n",
      "['Jalapeno', 'Pomegranate', 'Tomato', 'Pomelo', 'Apple']\n",
      "['Maracuja', 'Watermelon', 'Apple', 'Pomelo', 'Strawberry']\n",
      "['Orange', 'Cherry', 'Tamarillo', 'Tomato', 'Apple']\n",
      "['Pomegranate', 'Pomelo', 'Tomato', 'Orange', 'Apple']\n",
      "['Maracuja', 'Watermelon', 'Apple', 'Pomelo', 'Strawberry']\n",
      "['Cauliflower', 'Apple', 'Orange', 'Turnip', 'Garlic']\n"
     ]
    }
   ],
   "source": [
    "for item in prediction:\n",
    "    liste=[]\n",
    "    for pred in np.argsort(item)[-5:]:\n",
    "        liste.append(list_labels[pred])\n",
    "    print(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "count=0\n",
    "for i in range(len(base_model.layers)):\n",
    "    if i>=len(base_model.layers)*0.05:\n",
    "        base_model.layers[i].trainable = True\n",
    "        count+=1\n",
    "count\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-146-d0fcae88fb00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3000\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\boure\\anaconda3\\envs\\aifruits\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\boure\\anaconda3\\envs\\aifruits\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\boure\\anaconda3\\envs\\aifruits\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    955\u001b[0m       \u001b[1;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m       return self._concrete_stateful_fn._call_flat(\n\u001b[1;32m--> 957\u001b[1;33m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minner_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minner_kwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minner_filtered_flat_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\boure\\anaconda3\\envs\\aifruits\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1964\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\boure\\anaconda3\\envs\\aifruits\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\Users\\boure\\anaconda3\\envs\\aifruits\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "h = model.fit(train_batch, \n",
    "            epochs=50,\n",
    "            steps_per_epoch = 6000 // BATCH_SIZE,\n",
    "            validation_data = test_batch,\n",
    "            validation_steps = 3000 // BATCH_SIZE,\n",
    "            callbacks=tf.keras.callbacks.EarlyStopping(patience=3)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(img_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mangostan', 'Peas', 'Apple', 'Pomelo', 'Strawberry']\n",
      "['Redcurrant', 'Peas', 'Cherry', 'Pomelo', 'Apple']\n",
      "['Apple', 'Cucumber', 'Physalis', 'Mangostan', 'Caspicum']\n",
      "['Mangostan', 'Orange', 'Eggplant', 'Grape', 'Apple']\n",
      "['Cherry', 'Watermelon', 'Pomelo', 'Peas', 'Apple']\n",
      "['Mangostan', 'Peas', 'Apple', 'Pomelo', 'Strawberry']\n",
      "['Peas', 'Nut', 'Apple', 'Mangostan', 'Pomelo']\n",
      "['Papaya', 'Cauliflower', 'Peas', 'Turnip', 'Garlic']\n",
      "['Tomato', 'Apple', 'Pomelo', 'Cherry', 'Orange']\n",
      "['Orange', 'Pomegranate', 'Mangostan', 'Apple', 'Tomato']\n"
     ]
    }
   ],
   "source": [
    "for item in prediction:\n",
    "    liste=[]\n",
    "    for pred in np.argsort(item)[-5:]:\n",
    "        liste.append(list_labels[pred])\n",
    "    print(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"aifruits_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(img_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Caspicum', 'Mangostan', 'Tomato', 'Cherry', 'Apple']\n",
      "['Raddish', 'Peas', 'Apple', 'Pomelo', 'Strawberry']\n",
      "['Cherry', 'Tomato', 'Pomelo', 'Jalapeno', 'Apple']\n",
      "['Tomato', 'Beetroot', 'Apple', 'Mangostan', 'Pomelo']\n",
      "['Peas', 'Redcurrant', 'Physalis', 'Pomelo', 'Apple']\n",
      "['Cherry', 'Jalapeno', 'Orange', 'Pomelo', 'Apple']\n",
      "['Physalis', 'Cherry', 'Tomato', 'Tamarillo', 'Apple']\n",
      "['Orange', 'Cauliflower', 'Turnip', 'Apple', 'Garlic']\n",
      "['Raddish', 'Peas', 'Apple', 'Pomelo', 'Strawberry']\n",
      "['Watermelon', 'Caspicum', 'Physalis', 'Mangostan', 'Apple']\n"
     ]
    }
   ],
   "source": [
    "for item in prediction:\n",
    "    liste=[]\n",
    "    for pred in np.argsort(item)[-5:]:\n",
    "        liste.append(list_labels[pred])\n",
    "    print(liste)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a56e509252da22a4a4f93ae404dbc759abc3f6493d8365896b99c773e73ebf8f"
  },
  "kernelspec": {
   "display_name": "Python 3.6.15 ('aifruits')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
